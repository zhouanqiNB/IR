# fast_pagerank

我比较不理解的是，他这个作者为什么一定要对这个最终的打分做规范化（即令结果向量长度为1），这导致我看了图和代码之后，半天没懂他这个是什么意思。

代码：

```python
import numpy as np
from scipy import sparse
from fast_pagerank import pagerank
from fast_pagerank import pagerank_power

# 这是向量
A = np.array([[0,1], [0, 2], [1, 2],[2,0],[3,2]])
weights = [1,1,1,1,1]
G = sparse.csr_matrix((weights, (A[:,0], A[:,1])), shape=(4, 4))
pr=pagerank(G, p=0.85)
print(pr)
```

结果：

```
array([0.37252685, 0.19582391, 0.39414924, 0.0375    ])
```

原来的（谁看的出来这个A的1.49和0.3725有啥关系啊？）：

![img](https://github.com/asajadi/fast-pagerank/raw/master/example1.gif)

因为站长不太愿意让人爬，所以我只是基于已经爬到的数据，做了链接分析。主要的网页与网页之间的关系都是通过我目测得出来的，手动构建矩阵。。。

不过现在链接关系应该是没有问题，因为我详情页的URL是从目录页的html文件里提取得到的。

lastPageNumber=[16,17,7,14,3,3]

pageNumList=[73,4,7,14,6,4]

这个page rank算出来的数值还是比较科学的。比如在这个图里我们可以看到一号，也就是也就是说动画的首页它的权重是比较高的。然后后面我还我们还可以看到游戏、漫画等等的首页权重都比较高，这是因为你可以从这个网站的任意一个地方跳到这几个tab的首页，所以指向它的链接比较多。然后这个带来的一个后果是，我们本来可以想象，应该是所有的详情页都是一样的权重，事实上我们发现比如说在动画的首页，它指向的所有的详情页，它的权重会高一点。

![image-20211207005208534](C:/Users/16834/Desktop/%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E5%AE%9E%E9%AA%8C/4%20%E5%AE%9E%E9%AA%8C4%2012.12/image-20211207005208534.png)

![image-20211207005344923](C:/Users/16834/Desktop/%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E5%AE%9E%E9%AA%8C/4%20%E5%AE%9E%E9%AA%8C4%2012.12/image-20211207005344923.png)

我只是感觉这个数值没什么意思，所以我打算在算的时候，只给他零点1的权重。



我第一次建立的索引是单纯的只用来做高级搜索。第二次的索引可以和第三次的索引一起做全站搜索。所以我还得爬一次数据。