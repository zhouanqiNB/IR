# FANG: Leveraging Social Context for Fake News Detection Using Graph Representation

> 1911590周安琪_11.03\_论文笔记

## 1 基本信息

- **发表刊物：**CIKM, Conference on Information and Knowledge Management
- **发表年份：**2020
- **作者：**Van-Hoang Nguyen, Preslav Nakov, Kazunari Sugiyama, Min-Yen Kan
- **关键词（中文）：**假情报、假新闻、社交网络、图神经网络、表征学习
- **关键词（英文）：**Disinformation, Fake News, Social Networks, Graph Neural Networks, Representation Learning

## 2 论文内容

### 2.1 解决的问题

Fake news detection：在信息爆炸的互联网时代，假新闻变得越来越多，也更难以识别，准确识别需要耗费大量人工，本文研究的内容就是如何通过机器学习来辨别假新闻。

### 2.2 解决问题的方法

之前的一些工作考察了新闻传播过程中的 contextual features，他们发现==网民对真/假新闻的反应不一样==，这可以用于判断假新闻。

应用了图形神经网络的一些最新进展。

### 2.3 仍然存在的问题

1. 来自上游的差错会影响到FANG的结果。
2. 用于上下文假新闻检测的数据集可能很快就会过时，因为发布时的超链接和社交媒体痕迹可能不再能被检索到。

## 3 实验内容

### 3.1 实验采用的数据集

在一个相关工作收集的**Twitter数据集**上进行了实验。

对于每一篇文章，收集它的来源、参与用户的名单，以及他们的推文。这个数据集还包括Twitter的简介描述、每个用户关注的Twitter简介列表。

### 3.2 数据集内容是否和待解决问题模型对应

是

### 3.3 实验是否涉及实际应用场景

是，这本身就是一个应用性比较强的研究，idea也和现实生活非常相关。

### 3.4 实验任务

- 衡量对于真假新闻判断的结果正确性
- 测量程序的性能
- 测量在不同的数据集下的结果

### 3.5 实验衡量指标

- ROC下方的AUC
- performance
- 复杂度、可扩展性

<img src="C:/Users/16834/Desktop/%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E5%AE%9E%E9%AA%8C/2%20%E5%AE%9E%E9%AA%8C2%2011.7/image-20211103031004944.png" alt="image-20211103031004944" style="zoom:50%;" />

### 3.6 实验说明所提出的方法的优点

- Limited Training Data

  在有限的数据集下训练，相比别的工具效果不错。

- Engagement Temporality Study 

  收集了FANG生成的每个时间窗口的attention weights，并做了比较。最后发现本文模型的权重特点与人为的观察一致。

- Representation Learning

  提高了representation的质量

  - 单纯基于文本的表征，因为假新闻网站会模仿真新闻，所以效果不好。
  - 基于引用量的表征，GCN和FANG都使用了，但是没办法分辨引用率高的假新闻网站。

## 4 思考内容

- **选择论文的原因：**大二选过陈晨老师python课程，被Fake News Detection大作业劝退，据说今年还是这个作业。现在学分修不满十分后悔，打算看一看这个论文是怎么做的。

- **论文仍然可以改进的地方是什么：**我发现该论文存在部分语法问题，这使得我有的时候看不明白，连蒙带猜。

- **所选这篇论文和目前自己在做的内容能够想到的相关点：**这篇文章利用social context建模之后做了聚类，这种提取特征再分类的算法在各种各样的领域都可能遇到。不过这个步骤一般在后期，很多论文会专注于前期的有效的特征提取。我在做的主要是代码语义相似性检测，和本文的重合不多，这可能是为数不多的一个。

