{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作业一：布尔检索\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import nltk\n",
    "import numpy as np\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict\n",
    "sw = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对文本进行分词\n",
    "使用了NLTK工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(text):\n",
    "    text = re.sub(r\"[{}]+\".format(punctuation), \" \", text)  # 将标点符号转化为空格\n",
    "    text = text.lower()  # 全部字符转为小写\n",
    "    words = nltk.word_tokenize(text)  # 分词\n",
    "    words = list(set(words).difference(set(sw)))  # 去停用词\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取文本文件\n",
    "给定文本文件目录，获取目录下所有符合要求的文件列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(dir, file_type='.txt'):\n",
    "    file_list = []\n",
    "    for home, dirs, files in os.walk(dir):\n",
    "        for filename in files:\n",
    "            if file_type in filename:\n",
    "                file_list.append(os.path.join(home, filename))\n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 词法分析\n",
    "通过正则表达式对查询进行词法分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造每种类型词的正则表达式，()代表分组，?P<NAME>为组命名\n",
    "token_or = r'(?P<OR>\\|\\|)'\n",
    "token_not = r'(?P<NOT>\\!)'\n",
    "token_word = r'(?P<WORD>[a-zA-Z]+)'\n",
    "token_and = r'(?P<AND>&&)'\n",
    "token_lp = r'(?P<LP>\\()'\n",
    "token_rp = r'(?P<RP>\\))'\n",
    "lexer = re.compile('|'.join([token_or, token_not, token_word,\n",
    "                            token_and, token_lp, token_rp]))  # 编译正则表达式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用编译好的正则表达式进行词法分析\n",
    "def get_tokens(query):\n",
    "    tokens = []  # tokens中的元素类型为(token, token类型)\n",
    "    for token in re.finditer(lexer, query):\n",
    "        tokens.append((token.group(), token.lastgroup))\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 布尔检索类\n",
    "由构建索引、布尔表达式解析、结果查询与合并三部分组成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoolRetrieval:\n",
    "    \"\"\"\n",
    "    布尔检索类\n",
    "    index为字典类型，其键为单词，值为文件ID列表，如{\"word\": [1, 2, 9], ...}\n",
    "    \"\"\"\n",
    "    def __init__(self, index_path=''):\n",
    "        if index_path == '':\n",
    "            self.index = defaultdict(list)\n",
    "        # 已有构建好的索引文件\n",
    "        else:\n",
    "            data = np.load(index_path, allow_pickle=True)\n",
    "            self.files = data['files'][()]\n",
    "            self.index = data['index'][()]\n",
    "        self.query_tokens = []\n",
    "\n",
    "    def build_index(self, text_dir):\n",
    "        self.files = get_files(text_dir)  # 获取所有文件名\n",
    "        for num in range(0, len(self.files)):\n",
    "            f = open(self.files[num])\n",
    "            text = f.read()\n",
    "            words = get_words(text)  # 分词\n",
    "            # 构建倒排索引\n",
    "            for word in words:\n",
    "                self.index[word].append(num)\n",
    "        print(self.files, self.index)\n",
    "        np.savez('index.npz', files=self.files, index=self.index)\n",
    "\n",
    "    def search(self, query):\n",
    "        self.query_tokens = get_tokens(query)  # 获取查询的tokens\n",
    "        result = []\n",
    "        # 将查询得到的文件ID转换成文件名\n",
    "        for num in self.evaluate(0, len(self.query_tokens) - 1):\n",
    "            result.append(self.files[num])\n",
    "        return result\n",
    "\n",
    "    # 递归解析布尔表达式，p、q为子表达式左右边界的下标\n",
    "    def evaluate(self, p, q):\n",
    "        # 解析错误\n",
    "        if p > q:\n",
    "            return []\n",
    "        # 单个token，一定为查询词\n",
    "        elif p == q:\n",
    "            return self.index[self.query_tokens[p][0]]\n",
    "        # 去掉外层括号\n",
    "        elif self.check_parentheses(p, q):\n",
    "            return self.evaluate(p + 1, q - 1)\n",
    "        else:\n",
    "            op = self.find_operator(p, q)\n",
    "            if op == -1:\n",
    "                return []\n",
    "            # files1为运算符左边得到的结果，files2为右边\n",
    "            if self.query_tokens[op][1] == 'NOT':\n",
    "                files1 = []\n",
    "            else:\n",
    "                files1 = self.evaluate(p, op - 1)\n",
    "            files2 = self.evaluate(op + 1, q)\n",
    "            return self.merge(files1, files2, self.query_tokens[op][1])\n",
    "\n",
    "    # 判断表达式是否为 (expr)\n",
    "    # 判断表达式是否为 (expr)\n",
    "    def check_parentheses(self, p, q):\n",
    "        \"\"\"\n",
    "        判断表达式是否为 (expr)\n",
    "        整个表达式的左右括号必须匹配才为合法的表达式\n",
    "        返回True或False\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    # 寻找表达式的dominant的运算符（优先级最低）\n",
    "    def find_operator(self, p, q):\n",
    "        \"\"\"\n",
    "        寻找表达式的dominant的运算符（优先级最低）\n",
    "        其必定在括号外面（不存在整个子表达式被括号包围，前面以已处理）\n",
    "        返回dominant运算符的下标位置\n",
    "        \"\"\"\n",
    "        pass\n",
    "    def merge(self, files1, files2, op_type):\n",
    "        \"\"\"\n",
    "        根据运算符对进行相应的操作\n",
    "        在Python中可以通过集合的操作来实现\n",
    "        但为了练习算法，请遍历files1, files2合并\n",
    "        \"\"\"\n",
    "        result = []\n",
    "        \"\"\"\n",
    "        if op_type == 'AND':\n",
    "            result = list(set(files1) & set(files2))\n",
    "        elif op_type == \"OR\":\n",
    "            result = list(set(files1) | set(files2))\n",
    "        elif op_type == \"NOT\":\n",
    "            result = list(set(range(0, len(self.files))) - set(files2))\n",
    "        \"\"\"\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建布尔检索类对象\n",
    "第一次需要调用build_index()函数创建索引，之后可直接用索引文件进行初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['text\\\\advantages.txt', 'text\\\\bir.txt', 'text\\\\disadvantage.txt',\n",
       "       'text\\\\ir.txt'], dtype='<U21')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# br = BoolRetrieval()\n",
    "# br.build_index('text')\n",
    "br = BoolRetrieval('index.npz')\n",
    "br.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'clean': [0],\n",
       "             'intuitive': [0],\n",
       "             'concept': [0],\n",
       "             'easy': [0],\n",
       "             'formalism': [0],\n",
       "             'implement': [0],\n",
       "             'advantages': [0],\n",
       "             'theory': [1],\n",
       "             'used': [1],\n",
       "             'contain': [1],\n",
       "             'terms': [1, 2],\n",
       "             'information': [1, 2, 3],\n",
       "             'searched': [1],\n",
       "             'day': [1],\n",
       "             'retrieval': [1, 2, 3],\n",
       "             'documents': [1, 2, 3],\n",
       "             'ir': [1, 3],\n",
       "             'classical': [1],\n",
       "             'conceived': [1],\n",
       "             'logic': [1],\n",
       "             'many': [1, 2],\n",
       "             'bir': [1],\n",
       "             'set': [1],\n",
       "             'whether': [1],\n",
       "             'boolean': [1, 2],\n",
       "             'time': [1],\n",
       "             'based': [1, 2, 3],\n",
       "             'sets': [1],\n",
       "             'first': [1],\n",
       "             'adopted': [1],\n",
       "             'systems': [1],\n",
       "             'user': [1, 2],\n",
       "             'standard': [1],\n",
       "             'one': [1],\n",
       "             'model': [1, 2],\n",
       "             'query': [1, 2],\n",
       "             'translate': [2],\n",
       "             'returns': [2],\n",
       "             'weighted': [2],\n",
       "             'users': [2],\n",
       "             'retrieve': [2],\n",
       "             'queries': [2],\n",
       "             'like': [2],\n",
       "             'matching': [2],\n",
       "             'may': [2],\n",
       "             'binary': [2],\n",
       "             'need': [2, 3],\n",
       "             'find': [2],\n",
       "             'formulated': [2],\n",
       "             'exact': [2],\n",
       "             'expression': [2],\n",
       "             'response': [2],\n",
       "             'provided': [2],\n",
       "             'absence': [2],\n",
       "             'grading': [2],\n",
       "             'frequently': [2],\n",
       "             'decision': [2],\n",
       "             'translated': [2],\n",
       "             'either': [2],\n",
       "             'often': [2],\n",
       "             'disadvantages': [2],\n",
       "             'criteria': [2],\n",
       "             'equally': [2],\n",
       "             'partial': [2],\n",
       "             'simplistic': [2],\n",
       "             'ranking': [2],\n",
       "             'scale': [2],\n",
       "             'data': [2, 3],\n",
       "             'notion': [2],\n",
       "             'hard': [2],\n",
       "             'awkward': [2],\n",
       "             'metadata': [3],\n",
       "             'collection': [3],\n",
       "             'resources': [3],\n",
       "             'system': [3],\n",
       "             'searching': [3],\n",
       "             'relevant': [3],\n",
       "             'also': [3],\n",
       "             'science': [3],\n",
       "             'searches': [3],\n",
       "             'databases': [3],\n",
       "             'indexing': [3],\n",
       "             'text': [3],\n",
       "             'texts': [3],\n",
       "             'obtaining': [3],\n",
       "             'sounds': [3],\n",
       "             'content': [3],\n",
       "             'describes': [3],\n",
       "             'document': [3],\n",
       "             'full': [3],\n",
       "             'images': [3],\n",
       "             'activity': [3]})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "br.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请输入与查询（与||，或&&，非！）：boolean\n",
      "['text\\\\bir.txt', 'text\\\\disadvantage.txt']\n",
      "请输入与查询（与||，或&&，非！）：retrieval\n",
      "['text\\\\bir.txt', 'text\\\\disadvantage.txt', 'text\\\\ir.txt']\n",
      "请输入与查询（与||，或&&，非！）：boolean && retrieval\n",
      "['text\\\\bir.txt', 'text\\\\disadvantage.txt']\n",
      "请输入与查询（与||，或&&，非！）：boolean && retrieval || advantages\n",
      "['text\\\\bir.txt', 'text\\\\disadvantage.txt']\n",
      "请输入与查询（与||，或&&，非！）：(boolean && retrieval) || !disadvantages\n",
      "['text\\\\advantages.txt', 'text\\\\bir.txt', 'text\\\\disadvantage.txt', 'text\\\\ir.txt']\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    query = input(\"请输入与查询（与||，或&&，非！）：\")\n",
    "    print(br.search(query))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
